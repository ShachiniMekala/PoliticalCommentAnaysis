{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comments_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOz8NKDek+8fG/UbGmAD27Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShachiniMekala/PoliticalCommentAnaysis/blob/main/Comments_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g7tZNefeX99"
      },
      "source": [
        "# Background Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkQrzBgsb_sM",
        "outputId": "b094a484-5f40-489b-e209-4bf786c4641b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2SzAl13dK-R",
        "outputId": "698960f3-7557-4e93-f35d-c92178fd70c1"
      },
      "source": [
        "import os\n",
        "import string\n",
        "import nltk\n",
        "from nltk import FreqDist\n",
        "import pandas as pd\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W9-5ZoadOXI"
      },
      "source": [
        "#read corpus into dataframe\n",
        "df_comments = pd.read_csv(\"/content/gdrive/MyDrive/NLP/Comments.csv\") "
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlCq-tmWdn78"
      },
      "source": [
        "#select only positive comments\n",
        "df_positive = df_comments[df_comments[\"Annotation\"] == \"positive\"]\n",
        "df_positive_comments = df_positive['Comment']\n",
        "\n",
        "#select only negative comments\n",
        "df_negative = df_comments[df_comments[\"Annotation\"] == \"negative\"]\n",
        "df_negative_comments = df_negative['Comment']"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jCERBToegJv"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E0TLz6oemi4"
      },
      "source": [
        "def preprocessing(input_str):\n",
        "  output_str=''\n",
        "  punc = \"'\"+\"!\"+\"(\"+\")\"+\"-\"+\"[\"+\"]\"+\"{\"+\"}\"+\";\"+\":\"+\"\\\"\"+\",\"+\"<\"+\"+\"+\">\"+\".\"+\"/\"+\"?\"+\"@\"+\"#\"+\"$\"+\"%\"+\"^\"+\"&\"+\"*\"+\"_\"+\"~\"+\"\\\\\"\n",
        "\n",
        "  #remove punctuations in comment\n",
        "  for char in input_str:\n",
        "    if char not in punc:\n",
        "        output_str = output_str + char\n",
        "\n",
        "  output_str = output_str.strip()\n",
        "\n",
        "  #annotate the begining and the end of the sentence\n",
        "  output_str = \"<\" + output_str + \">\"\n",
        "\n",
        "  #convert the string into lower case and tokenize\n",
        "  word_tokens = nltk.word_tokenize(output_str.lower())\n",
        "  \n",
        "  return word_tokens"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSh0HnsGL6F9"
      },
      "source": [
        "# Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u25bMsb4vxqc"
      },
      "source": [
        "unigram_list_p=[]\n",
        "bigram_list_p=[]\n",
        "unigram_list_n=[]\n",
        "bigram_list_n=[]\n",
        "positive_tokens_t=[]\n",
        "negative_tokens_t=[]\n",
        "\n",
        "#preprocess positive comments\n",
        "for comment in df_positive_comments:\n",
        " positive_tokens = preprocessing(comment)\n",
        " #list the unigrams in the positive corpus\n",
        " unigram_list_p = unigram_list_p + list(positive_tokens)\n",
        " #list the bigrams in the positive corpus\n",
        " bigrams_p = nltk.bigrams(positive_tokens)\n",
        " bigram_list_p = bigram_list_p + list(bigrams_p)\n",
        " #concatenate all the words in positive corpus to take the unique word count\n",
        " positive_tokens_t=positive_tokens_t + positive_tokens\n",
        "\n",
        "#preprocess negative comments\n",
        "for comment in df_negative_comments:\n",
        " negative_tokens = preprocessing(comment)\n",
        " #list the unigrams in the negative corpus\n",
        " unigram_list_n = unigram_list_n + list(negative_tokens)\n",
        " #list the bigrams in the negative corpus\n",
        " bigrams_n = nltk.bigrams(negative_tokens)\n",
        " bigram_list_n = bigram_list_n + list(bigrams_n)\n",
        " #concatenate all the words in negative corpus to take the unique word count\n",
        " negative_tokens_t=negative_tokens_t+negative_tokens\n"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8MVL9AFJKs6",
        "outputId": "8e819cc2-817b-4fe4-fcc4-813d92e3cfde"
      },
      "source": [
        "#unique word count in corpus\n",
        "unique_count = len(set(positive_tokens_t)) + len(set(negative_tokens_t))\n",
        "unique_count"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faiCyndvFExo"
      },
      "source": [
        "#frequency distribution for positive unigrams and bigrams\n",
        "unigram_freq_p = FreqDist(unigram_list_p)\n",
        "bigram_freq_p = FreqDist(bigram_list_p)\n",
        "\n",
        "#frequency distribution for negative unigrams and bigrams\n",
        "unigram_freq_n = FreqDist(unigram_list_n)\n",
        "bigram_freq_n = FreqDist(bigram_list_n)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG1L0nv5MHFg"
      },
      "source": [
        "# Input Comment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEwmYlWD0P5j",
        "outputId": "b7f275b4-415b-4abd-f919-0e241f202a09"
      },
      "source": [
        "#prerocess input comment\n",
        "input_comment = input()\n",
        "\n",
        "#preprocess the input comment\n",
        "input_tokens=preprocessing(input_comment)\n",
        "input_bigrams = list(nltk.bigrams(input_tokens))\n",
        "\n",
        "#word count in input comment\n",
        "word_count_input = len(input_tokens)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gota ta mun meka karanan den na\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-emtl1D3MMnU"
      },
      "source": [
        "# Calculate Probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKXLQSOM1K0F",
        "outputId": "28ab6c72-25fc-4d82-ddf9-8b4e8e8760c5"
      },
      "source": [
        "probability_p = 1.0\n",
        "# calculate the probability of being positive\n",
        "\n",
        "for bigram in range(len(input_bigrams)):\n",
        "\n",
        " if input_bigrams[bigram] in bigram_freq_p:\n",
        "  prob_bigram = bigram_freq_p[input_bigrams[bigram]]\n",
        " else:\n",
        "  prob_bigram = 0 \n",
        " \n",
        " if input_bigrams[bigram][0] in unigram_freq_p:\n",
        "  prob_unigram = unigram_freq_p[input_bigrams[bigram][0]]\n",
        " else:\n",
        "  prob_unigram = 0\n",
        "\n",
        " #laplace smoothing\n",
        "  prob_after_smoothing = (prob_bigram + 1) / (prob_unigram + unique_count)\n",
        "\n",
        " #probability of being positive\n",
        "  probability_p = probability_p * (prob_after_smoothing)\n",
        "\n",
        "print('Probability of being POSITIVE : '+str(probability_p))\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability of being POSITIVE : 6.3937337358319145e-15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj3i2twIMhoO",
        "outputId": "f2e75dbc-145f-46d2-e2fe-4ec5c5087aa6"
      },
      "source": [
        "probability_n = 1.0\n",
        "# calculate the probability of being negative\n",
        "for bigram in range(len(input_bigrams)):\n",
        "\n",
        " if input_bigrams[bigram] in bigram_freq_n:\n",
        "  prob_bigram = bigram_freq_n[input_bigrams[bigram]]\n",
        " else:\n",
        "  prob_bigram = 0 \n",
        " \n",
        " if input_bigrams[bigram][0] in unigram_freq_n:\n",
        "  prob_unigram = unigram_freq_n[input_bigrams[bigram][0]]\n",
        " else:\n",
        "  prob_unigram = 0\n",
        "\n",
        " #laplace smoothing\n",
        "  prob_after_smoothing = (prob_bigram + 1) / (prob_unigram + unique_count)\n",
        "\n",
        " #probability of being positive\n",
        "  probability_n = probability_n * (prob_after_smoothing)\n",
        "\n",
        "print('Probability of being NEGATIVE : '+str(probability_n))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability of being NEGATIVE : 4.411676277724021e-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg6T_CkTb43C"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WJSvdA8bqQJ",
        "outputId": "0063fe92-15cc-4e70-fc02-429336260fd7"
      },
      "source": [
        "if probability_p > probability_n:\n",
        " print(\"Input is a POSITIVE comment\")\n",
        " perplexity=pow(probability_p, (-1 / word_count_input))\n",
        " print(\"Perplexity : \"+str(perplexity))\n",
        "\n",
        "else:\n",
        " if probability_p < probability_n:\n",
        "  print(\"Input is a NEGATIVE comment\")\n",
        "  perplexity=pow(probability_n, (-1 / word_count_input))\n",
        "  print(\"Perplexity : \"+str(perplexity))\n",
        " else:\n",
        "  print(\"Failed to Classify\")"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input is a NEGATIVE comment\n",
            "Perplexity : 18.26882884295643\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}